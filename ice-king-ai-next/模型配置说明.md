# 模型配置说明

## 🤖 灵活的模型选择

现在所有AI模型相关配置都可以通过环境变量自定义，让您可以根据需要选择最适合的模型。

## 📋 配置项说明

### 1. 基础配置
```env
# OpenAI API密钥 (必需)
OPENAI_API_KEY=your_api_key_here

# 自定义Base URL (可选)
OPENAI_BASE_URL=https://api.openai.com/v1
```

### 2. 模型配置 (核心更新)
```env
# AI模型选择 (默认: gpt-3.5-turbo)
OPENAI_MODEL=gpt-3.5-turbo

# 生成参数配置
OPENAI_TEMPERATURE=0.8                # 创造性 (0-1)
OPENAI_MAX_TOKENS=2000                # 最大生成长度
```

## 🎯 常用模型推荐

### OpenAI 系列
```env
# 高质量，成本较高
OPENAI_MODEL=gpt-4

# 平衡性能，推荐
OPENAI_MODEL=gpt-4-turbo

# 低成本，速度快，推荐日常使用
OPENAI_MODEL=gpt-3.5-turbo
```

### 第三方提供商
```env
# 硅基流动 (性价比高)
OPENAI_BASE_URL=https://api.siliconflow.cn/v1
OPENAI_MODEL=deepseek-chat

# DeepSeek (中文优化，代码能力强)
OPENAI_BASE_URL=https://api.deepseek.com/v1
OPENAI_MODEL=deepseek-chat

# 月之暗面 (长文本处理)
OPENAI_BASE_URL=https://api.moonshot.cn/v1
OPENAI_MODEL=moonshot-v1-8k

# 智谱AI (中文优化)
OPENAI_BASE_URL=https://api.zhipuai.cn/v2
OPENAI_MODEL=glm-4

# 通义千问 (阿里云)
OPENAI_BASE_URL=https://api.qwenlm.cn/v1
OPENAI_MODEL=qwen-turbo
```

### MiniMax (海螺AI)
```env
OPENAI_BASE_URL=https://api.minimax.chat/v1/text/chatcompletion_v2
OPENAI_MODEL=abab6.5s-chat
```

### 讯飞星火
```env
OPENAI_BASE_URL=https://spark-api-open.xf-yun.com/v1
OPENAI_MODEL=general
```

### 火山引擎 (豆包)
```env
OPENAI_BASE_URL=https://ark.cn-beijing.volces.com/api/v3
OPENAI_MODEL=doubao-lite-4k
```

## ⚙️ 参数调优

### 创造性控制 (Temperature)
```env
# 保守生成，适合精确内容
OPENAI_TEMPERATURE=0.3

# 平衡创造性和一致性 (推荐)
OPENAI_TEMPERATURE=0.8

# 高创造性，适合创意内容
OPENAI_TEMPERATURE=1.0
```

### 内容长度控制 (Max Tokens)
```env
# 短内容生成
OPENAI_MAX_TOKENS=1000

# 中等长度 (推荐)
OPENAI_MAX_TOKENS=2000

# 长内容生成
OPENAI_MAX_TOKENS=4000
```

## 🧪 测试不同模型

### 方法1: 修改.env.local
```bash
# 编辑配置文件
nano .env.local

# 修改模型配置
OPENAI_MODEL=deepseek-chat
OPENAI_TEMPERATURE=0.7
```

### 方法2: 强制API调用测试
访问 http://localhost:3000/simple-test.html
- 系统会显示当前使用的模型信息
- 观察API调用日志中的模型参数

### 方法3: 命令行测试
```bash
curl http://localhost:3000/api/test
```

## 💰 成本优化建议

### 1. 按需选择模型
- **日常测试**: `gpt-3.5-turbo` (最低成本)
- **正式内容**: `gpt-4-turbo` (性价比高)
- **高端需求**: `gpt-4` (最高质量)

### 2. 参数调优
- 降低 `temperature` 减少不必要的创造性
- 控制 `max_tokens` 避免过长生成

### 3. 缓存利用
- 相同输入会缓存结果
- 二次生成成本接近零

## 🔧 故障排除

### 模型不支持
```
Error: The model `xxx` does not exist
```
**解决方案**: 检查模型名称是否正确，参考各平台支持的模型列表

### Base URL错误
```
Error: 404 Not Found
```
**解决方案**: 确认Base URL格式正确，以/v1结尾

### 参数无效
```
Error: Invalid parameter
```
**解决方案**: 
- `temperature` 必须在 0-1 之间
- `max_tokens` 必须为正整数

## 📊 性能对比

| 模型 | 质量 | 速度 | 成本 | 推荐场景 |
|------|------|------|------|----------|
| gpt-4 | ⭐⭐⭐⭐⭐ | ⭐⭐ | $$$$ | 高端内容创作 |
| gpt-4-turbo | ⭐⭐⭐⭐ | ⭐⭐⭐ | $$$ | 正式内容生成 |
| gpt-3.5-turbo | ⭐⭐⭐ | ⭐⭐⭐⭐ | $$ | 日常使用 |
| deepseek-chat | ⭐⭐⭐⭐ | ⭐⭐⭐⭐ | $ | 中文内容，优化成本 |
| glm-4 | ⭐⭐⭐ | ⭐⭐⭐⭐ | $ | 中文优化 |

---

**现在您可以根据具体需求灵活配置最适合的AI模型！**